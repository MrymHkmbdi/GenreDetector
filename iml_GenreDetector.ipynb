{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iml-GenreDetector.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMnHupnFEs4iRclxTtVu05r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrymHkmbdi/GenreDetector/blob/main/iml_GenreDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWDbgDC-2uUp"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77BbSU3R4hgA"
      },
      "source": [
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.stem import PorterStemmer\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE-kayMh8Nf5"
      },
      "source": [
        "pip install clean-text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhEYFHHe8Q2-"
      },
      "source": [
        "from cleantext import clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6T4bDCW2r1s"
      },
      "source": [
        "train_set = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/GenreDetector/train.csv', encoding='Windows-1252')\n",
        "test_set = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/GenreDetector/test.csv', encoding='Windows-1252')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC8w9l1t3KuZ"
      },
      "source": [
        "train_set.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMWAEiti4TMk"
      },
      "source": [
        "all_genres = []\n",
        "for i in range(1,len(test_set)):\n",
        "    temp = test_set.loc[i,\"genres\"].replace(\"\\'\", \"\\\"\")\n",
        "    temp= json.loads(temp)\n",
        "    a=[d['name'] for d in temp]\n",
        "    for a1 in a:\n",
        "        if( not (a1 in all_genres)):\n",
        "            all_genres.append(a1)\n",
        "print(all_genres)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVXEGNfN3zWI"
      },
      "source": [
        "df_lables=[]\n",
        "column_names=[]\n",
        "for i  in range(0,20):\n",
        "    column_names.append(str(i))\n",
        "\n",
        "df_lables = pd.DataFrame(columns = column_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7NW_OXD34Fe"
      },
      "source": [
        "df_lables.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lphDad5r6qYf"
      },
      "source": [
        "df_lables.to_csv(\"/content/drive/MyDrive/Colab Notebooks/GenreDetector/test_lables.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2qiBuYbAXz2"
      },
      "source": [
        "df_lables.to_csv(\"/content/drive/MyDrive/Colab Notebooks/GenreDetector/train_lables.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6Z6QhMR8Itt"
      },
      "source": [
        "genres = ['Action', 'Adventure', 'Horror', 'Thriller', 'Science Fiction', 'Drama', 'Family', 'Animation', 'History', 'Romance', 'Crime', 'Comedy', 'Music', 'War', 'Fantasy', 'Mystery', 'Documentary', 'Foreign', 'Western']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SReSR7F-9aZb"
      },
      "source": [
        "train_set=train_set.fillna(0)\n",
        "test_set=test_set.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9x7RxnK66oo"
      },
      "source": [
        "cleans_data=[]\n",
        "df_vectors= []\n",
        "ps = PorterStemmer()\n",
        "for i in range(0,len(test_set)):\n",
        "    vector=[0]*20    \n",
        "    temp = test_set.loc[i,\"genres\"].replace(\"\\'\", \"\\\"\")\n",
        "    temp= json.loads(temp)\n",
        "    a=[d['name'] for d in temp]\n",
        "    for a1 in a:\n",
        "        j=genres.index(a1)\n",
        "        df_lables.loc[i,str(j)]=1\n",
        "        vector[j]=1\n",
        "    df_vectors.append(vector)\n",
        "    clean_data=clean(test_set.loc[i,\"overview\"],\n",
        "        fix_unicode=True,               # fix various unicode errors\n",
        "        to_ascii=True,                  # transliterate to closest ASCII representation\n",
        "        lower=True,                     # lowercase text\n",
        "        no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
        "        no_urls=True,                  # replace all URLs with a special token\n",
        "        no_emails=True,                # replace all email addresses with a special token\n",
        "        no_phone_numbers=True,         # replace all phone numbers with a special token\n",
        "        no_numbers=False,               # replace all numbers with a special token\n",
        "        no_digits=False,                # replace all digits with a special token\n",
        "        no_currency_symbols=True,      # replace all currency symbols with a special token\n",
        "        no_punct=True,                 # remove punctuations\n",
        "        replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
        "        replace_with_url=\"<URL>\",\n",
        "        replace_with_email=\"<EMAIL>\",\n",
        "        replace_with_phone_number=\"<PHONE>\",\n",
        "        replace_with_number=\"<NUMBER>\",\n",
        "        replace_with_digit=\"0\",\n",
        "        replace_with_currency_symbol=\"<CUR>\",\n",
        "        lang=\"en\"                       # set to 'de' for German special handling\n",
        "    )\n",
        "    clean_data_col=\"\"\n",
        "    words=re.sub(\"[^\\w]\", \" \", clean_data).split()\n",
        "    for w in words:\n",
        "        clean_data_col = clean_data_col + \" \"+ ps.stem(w)\n",
        "    test_set.loc[i,\"clean_data\"]=clean_data_col\n",
        "    cleans_data.append(clean_data_col)\n",
        "test_set[\"clean\"]=cleans_data\n",
        "test_set.to_csv(\"/content/drive/MyDrive/Colab Notebooks/GenreDetector/cleaned_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqPzCx5288LZ"
      },
      "source": [
        "def get_mean_vector(word2vec_model, words):\n",
        "    # remove out-of-vocabulary words\n",
        "    words=re.sub(\"[^\\w]\", \" \",  words).split()\n",
        "    sent_vec = np.zeros(25) # as word vectors are of zero length 50, \n",
        "    #you might need to change this to 300 if you use google's w2v\n",
        "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
        "    \n",
        "    for word in words: # for each word in a review/sentence\n",
        "        if word in word_vectors:\n",
        "            vec = wv[word]\n",
        "            sent_vec += vec\n",
        "            cnt_words += 1\n",
        "    if cnt_words != 0:\n",
        "        sent_vec /= cnt_words\n",
        "    return sent_vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6nO6zp7-nr_"
      },
      "source": [
        "import gensim.downloader\n",
        "from gensim.test.utils import common_texts\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(sentences=common_texts,window=5, min_count=1, workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXtf-5ID-jsj",
        "outputId": "04fd9625-8be0-447e-dbe9-1b0388e463f6"
      },
      "source": [
        "glove_vectors = gensim.downloader.load('glove-twitter-25')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf77QCzo-XEA"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Store just the words + their trained embeddings.\n",
        "\n",
        "word_vectors = glove_vectors.wv\n",
        "\n",
        "word_vectors.save(\"word2vec.wordvectors\")\n",
        "\n",
        "# Load back with memory-mapping = read-only, shared across processes.\n",
        "\n",
        "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwMtbUaE92FS"
      },
      "source": [
        "meanvectors=[]\n",
        "for i in range(0,len(train_set)):\n",
        "    mean_vector=get_mean_vector(wv,str(train_set.loc[i,\"overview\"]))\n",
        "    meanvectors.append(mean_vector)\n",
        "meanvectors[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtKM_xJp9801"
      },
      "source": [
        "train_set[\"word2vec\"]=meanvectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdgv4AxT_q19"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdQZcsBWAbxP"
      },
      "source": [
        "meanvectors_test=[]\n",
        "for i in range(0,len(test_set)):\n",
        "    mean_vector=get_mean_vector(wv,str(test_set.loc[i,\"overview\"]))\n",
        "    meanvectors_test.append(mean_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0IPP3JnBH9W"
      },
      "source": [
        "test_set[\"word2vec\"]=meanvectors_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpZUteyyBl9L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}